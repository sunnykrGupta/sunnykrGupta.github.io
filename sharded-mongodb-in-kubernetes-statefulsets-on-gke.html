<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="https://sunnykrGupta.github.io/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="https://sunnykrGupta.github.io/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="https://sunnykrGupta.github.io/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Sunny Kumar">
  <meta name="description" content="Posts and writings by Sunny Kumar">


<meta name="keywords" content="Kubernetes, Mongodb, StatefulSets">

  <title>
    Daemon Blog
&ndash; Sharded Mongodb in Kubernetes StatefulSets on GKE  </title>

<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-63834161-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>
  <aside>
    <div id="user_meta">
      <a id="user_meta_logo" href="https://sunnykrGupta.github.io">
        <img src="https://sunnykrGupta.github.io/images/logo.jpg" alt="logo">
      </a>
      <h3><a href="https://sunnykrGupta.github.io">Sunny Kumar</a></h3>
      <p>Little wisdom of coding &Phi;  &#9679; Cloud Engineer, DevOps &Xi;  &#9679;  Football Lover &infin; &#9679; </p>

      <hr>

      <nav>
          <!--
          <h4><a href="https://sunnykrGupta.github.io/pages/projects.html">Projects</a></h4>
          -->
          <h4><a href="https://sunnykrGupta.github.io/pages/about-me.html">About</a></h4>
         <!--
          <h4><a href="https://sunnykrGupta.github.io/pages/contact-me.html">Contact</a></h4>
        -->
      </nav>
    </div>
  </aside>

  <main>
    <header>
      <nav>
          <a id="github" href="https://github.com/sunnykrGupta" target="_blank"><img src="https://sunnykrGupta.github.io/theme/images/Mono/webicon-github.png" alt="github"></a>
          <a id="twitter" href="https://twitter.com/Sunny_KrGupta" target="_blank"><img src="https://sunnykrGupta.github.io/theme/images/Mono/webicon-twitter.png" alt="twitter"></a>
          <a id="linkedin" href="https://www.linkedin.com/in/sunnykrgupta/" target="_blank"><img src="https://sunnykrGupta.github.io/theme/images/Mono/webicon-linkedin.png" alt="linkedin"></a>
          <a id="medium" href="https://medium.com/@sunnykrgupta/" target="_blank"><img src="https://sunnykrGupta.github.io/theme/images/Mono/webicon-medium.png" alt="medium"></a>
          <a id="mail" href="mailto:sunnygupta.kr@gmail.com" target="_blank"><img src="https://sunnykrGupta.github.io/theme/images/Mono/webicon-mail.png" alt="mail"></a>
      </nav>
      <br />
      <p>
        <a href="https://sunnykrGupta.github.io/index.html">Index</a> &nbsp;&nbsp; &brvbar; <a href="https://sunnykrGupta.github.io/archives.html">&nbsp;&nbsp;Archives</a>
      </p>

    </header>

<article>
  <div class="article_title">
    <h3><a href="https://sunnykrGupta.github.io/sharded-mongodb-in-kubernetes-statefulsets-on-gke.html">Sharded Mongodb in Kubernetes StatefulSets on GKE</a></h3>
  </div>
  <div class="article_text">
    <p><img alt="MongoDB in K8s" src="/images/kubes/k8s-mongodb.png"></p>
<p>This blog is going to demonstrate the setup of Sharded MongoDB Cluster on Google Kubernetes Engine. We will use kubernetes StatefulSets feature to deploy mongodb containers.</p>
<p>We need to cover some concepts before we move on to demonstration.</p>
<h3><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset">StatefulSets</a></h3>
<p>A StatefulSets is like a Deployment which manages Pods and guarantees about the ordering and uniqueness of these Pods.
It maintains a sticky identity for each of their Pods. It helps in deployment of application that needs persistency, unique network identifiers (DNS, Hostnames etc) and are meants for stateful application. If a pod gets terminated or deleted, a volume data will still remain intact if managed by persistentvolumes.  </p>
<h3><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#gce">StorageClass</a></h3>
<p>StorageClass helps in administration to describe the “classes” of storage offered by Kubernetes. Each StorageClass has different provisioner (GCEPersistentDisk, AWSElasticBlockStore, AzureDisk etc) that determines what volume plugin is used for provisioning storage.</p>
<h3><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">PersistentVolume</a></h3>
<p>A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator. PVs are resources available to be used by any Pod. Any Pod can claim these volumes by mean of PersistentVolumeClaims (PVC) and released eventually when claim is deleted.</p>
<h3><a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">Headless Services</a></h3>
<p>Headless Services are used to configure DNS of pods having same selectors defined by services. It is not generally used for load-balancing purpose. Each headless services configured with label selectors helps in defining unique network identifiers for pods running in statefulset.</p>
<p><br></p>
<hr>
<p><br></p>
<p>Lets begins the demonstration. Please switch to your terminal and follow the instructions.  </p>
<blockquote>
<p>Note : This setup is compatible with &lt;= mongo 3.2.</p>
</blockquote>
<h3>1. Prerequisites</h3>
<p>Ensure the following dependencies are already fulfilled on your host Linux system:</p>
<ol>
<li>GCP’s cloud client command line tool <a href="https://cloud.google.com/sdk/docs/quickstarts">gcloud</a></li>
<li>gcloud authentication to a project to manage container engine.</li>
<li>Install the Kubernetes command tool (“kubectl”),</li>
<li>Configure kubernetes authentication credentials.</li>
</ol>
<p><br></p>
<hr>
<p><br></p>
<h3>2. Create namespace, storageclass, Google compute Disk and persistentvolumes.</h3>
<p>Our Mongodb Setup will be as follows :</p>
<ul>
<li>1x Config Server  (k8s deployment type: "StatefulSet")</li>
<li>2x Shards with each Shard being a Replica Set containing 1x replicas (k8s deployment type: "StatefulSet")</li>
<li>2x Mongos Routers (k8s deployment type: "Deployment")</li>
</ul>
<p>We will create a kubernetes namespace and will deploy all our above resources in our defined namespaces. We will define disk that will be used by our statefulset containers. Disk will be mounted on pods running our mongodb server by means of APIs defined in StorageClass and PersistentVolume.</p>
<hr>
<h4>2.1 Create Namespace</h4>
<p>Create a file as <code>namespace.yaml</code> and replace <code>NAMESPACE_ID</code> with your handle name or any other name. I will create a namespace with <code>daemonsl</code>.</p>
<div class="highlight"><pre><span></span>#namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: NAMESPACE_ID
</pre></div>


<div class="highlight"><pre><span></span>#To apply resources to kubernetes, run
sed -e &quot;s/NAMESPACE_ID/daemonsl/g&quot; namespace.yaml &gt; tmp-namespace.yaml
kubectl apply -f tmp-namespace.yaml

#To verify namespaces
kubectl get ns
</pre></div>


<hr>
<h4>2.2 Create StorageClass</h4>
<p>Create a file as <code>gce-ssd-storageclass.yaml</code>. We are defining our storageclass name as <strong><code>fast</code></strong> and using GCE persistent disk as our provisioner with <code>type: pd-ssd</code> to allow SSD disk type allocation to requester (ie, statefulset container here).</p>
<div class="highlight"><pre><span></span>#gce-ssd-storageclass.yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-ssd
</pre></div>


<div class="highlight"><pre><span></span>#To apply resources to kubernetes, run
kubectl apply -f gce-ssd-storageclass.yaml

#To verify storageclass
kubectl get sc
</pre></div>


<hr>
<h4>2.3 Create GCE SSD Disks</h4>
<p>We will create some disk to be used by mongodb statefulset container. We are ordering two <code>10GB</code> disk and one <code>5GB</code> disk of type <code>SSD</code>.</p>
<div class="highlight"><pre><span></span>#For MainDB servers
gcloud compute disks create --size 10GB --type pd-ssd pd-ssd-disk-k8s-mongodb-daemonsl-10g-1
gcloud compute disks create --size 10GB --type pd-ssd pd-ssd-disk-k8s-mongodb-daemonsl-10g-2

#For Config servers
gcloud compute disks create --size 5GB --type pd-ssd pd-ssd-disk-k8s-mongodb-daemonsl-5g-1
</pre></div>


<hr>
<h4>2.4 Create PersistentVolume</h4>
<p>Create a file as <code>ext4-gce-ssd-persistentvolume.yaml</code>. We are defining our PersistentVolume storage capacity <code>10GB</code> to be bounded by <code>maindb</code> pod and <code>5GB</code> to be bounded by <code>configdb</code> pod.</p>
<div class="highlight"><pre><span></span>#ext4-gce-ssd-persistentvolume.yaml
apiVersion: &quot;v1&quot;
kind: &quot;PersistentVolume&quot;
metadata:
  name: data-volume-k8s-mongodb-daemonsl-SIZEg-INSTANCE
spec:
  capacity:
      storage: SIZEGi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: fast
  gcePersistentDisk:
    fsType: ext4
    pdName: pd-ssd-disk-k8s-mongodb-daemonsl-SIZEg-INSTANCE
</pre></div>


<p>Use above template, modify and apply in following order :</p>
<div class="highlight"><pre><span></span>#Replace &#39;SIZE&#39; with 10 and &#39;INSTANCE&#39; with 1,
# Ex: data-volume-k8s-mongodb-daemonsl-10g-1, storage: 10Gi,
sed -e &quot;s/INSTANCE/1/g; s/SIZE/10/g&quot; ext4-gce-ssd-persistentvolume.yaml &gt; tmp-ext4-gce-ssd-persistentvolume.yaml
kubectl apply -f tmp-ext4-gce-ssd-persistentvolume.yaml

#Replace &#39;SIZE&#39; with 10 and &#39;INSTANCE&#39; with 2
sed -e &quot;s/INSTANCE/2/g; s/SIZE/10/g&quot; ext4-gce-ssd-persistentvolume.yaml &gt; tmp-ext4-gce-ssd-persistentvolume.yaml
kubectl apply -f tmp-ext4-gce-ssd-persistentvolume.yaml

#Replace &#39;SIZE&#39; with 5 and &#39;INSTANCE&#39; with 1
sed -e &quot;s/INSTANCE/1/g; s/SIZE/5/g&quot; ext4-gce-ssd-persistentvolume.yaml &gt; tmp-ext4-gce-ssd-persistentvolume.yaml
kubectl apply -f tmp-ext4-gce-ssd-persistentvolume.yaml


#To verify PersistentVolume creation,
kubectl get pv
</pre></div>


<p>Now we have <strong>storageclass, namespace, disks</strong> and <strong>persistentvolume</strong> ready as resources for statefulset container.</p>
<p><br></p>
<hr>
<p><br></p>
<h3>3. StatefulSet containers and Mongos Deployment.</h3>
<h4>3.1 Statefulset ConfigDB</h4>
<p>Create a file as <code>mongodb-configdb-service-stateful.yaml</code> and copy the following template. Replace <code>NAMESPACE_ID</code> with <code>daemonsl</code>, or whatever name you have defined and <code>DB_DISK</code> with <code>5Gi</code>.</p>
<p>We have created a headless service with clusterIP <code>None</code> with selector as <code>role: mongodb-configdb</code> listening to port <code>27019</code>. We have defined our statefulset definition with mongodb arguments and volumeClaimTemplates. Here, <code>VolumeClaimTemplates</code> is requesting storageclass <code>fast</code> with <code>storage capacity 5GB</code>. This volumeClaimTemplates register this requests to storageclass and storageclass fulfill this requests by  <code>PersistentVolume (PV)</code> and register claim in <code>PersistentVolumeClaims (PVC)</code>.</p>
<div class="highlight"><pre><span></span>#mongodb-configdb-service-stateful.yaml
apiVersion: v1
kind: Service
metadata:
  name: mongodb-configdb-headless-service
  namespace: NAMESPACE_ID
  labels:
    name: mongodb-configdb
spec:
  ports:
  - port: 27019
    targetPort: 27019
  clusterIP: None
  selector:
    role: mongodb-configdb
---
apiVersion: apps/v1beta2  #change this version based on master version
kind: StatefulSet
metadata:
  name: mongodb-configdb
  namespace: NAMESPACE_ID
spec:
  selector:
    matchLabels:
      role: mongodb-configdb # has to match .spec.template.metadata.labels
  serviceName: mongodb-configdb-headless-service
  replicas: 1
  template:
    metadata:
      labels:
        role: mongodb-configdb
        tier: configdb
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: tier
                  operator: In
                  values:
                  - configdb
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 10
      containers:
        - name: mongodb-configdb-container
          image: mongo
          command:
            - &quot;mongod&quot;
            - &quot;--port&quot;
            - &quot;27019&quot;
            - &quot;--dbpath&quot;
            - &quot;/mongo-disk&quot;
            - &quot;--bind_ip&quot;
            - &quot;0.0.0.0&quot;
            - &quot;--configsvr&quot;
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          ports:
            - containerPort: 27019
          volumeMounts:
            - name: mongodb-configdb-persistent-storage-claim
              mountPath: /mongo-disk
  volumeClaimTemplates:
  - metadata:
      name: mongodb-configdb-persistent-storage-claim
      annotations:
        volume.beta.kubernetes.io/storage-class: &quot;fast&quot;
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      resources:
        requests:
          storage: DB_DISK
</pre></div>


<div class="highlight"><pre><span></span>sed -e &quot;s/NAMESPACE_ID/daemonsl/g; s/DB_DISK/5Gi/g&quot;  mongodb-configdb-service-stateful.yaml &gt; tmp-mongodb-configdb-service-stateful.yaml
kubectl apply -f tmp-mongodb-configdb-service-stateful.yaml
</pre></div>


<hr>
<h4>3.2 Statefulset mainDB</h4>
<p>Create a file as <code>mongodb-maindb-service-stateful.yaml</code> and copy the following template. Replace <code>NAMESPACE_ID</code> with <code>daemonsl</code>, or whatever name you have defined, <code>DB_DISK</code> with <code>10Gi</code> and <code>shardX</code> &amp; <code>ShardX</code> to <code>1</code> and then <code>2</code> and apply template two times to create two different statefulsets configuration. After deploying in kubernetes, we will have two statefulsets running with name as <code>mongodb-shard1</code> and <code>mongodb-shard2</code></p>
<p>Here again, We have created headless service and <code>VolumeClaimTemplates</code> which is requesting storageclass <code>fast</code> with storage capacity 10GB.kubectl apply -f tmp-ext4-gce-ssd-persistentvolume.yaml</p>
<div class="highlight"><pre><span></span>#mongodb-maindb-service-stateful.yaml
apiVersion: v1
kind: Service
metadata:
  name: mongodb-shardX-headless-service
  namespace: NAMESPACE_ID
  labels:
    name: mongodb-shardX
spec:
  ports:
  - port: 27017
    targetPort: 27017
  clusterIP: None
  selector:
    role: mongodb-shardX
---
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: mongodb-shardX
  namespace: NAMESPACE_ID
spec:
  selector:
    matchLabels:
      role: mongodb-shardX # has to match .spec.template.metadata.labels
  serviceName: mongodb-shardX-headless-service
  replicas: 1
  template:
    metadata:
      labels:
        role: mongodb-shardX
        tier: maindb
        replicaset: ShardX
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: replicaset
                  operator: In
                  values:
                  - ShardX
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 10
      containers:
        - name: mongodb-shardX-container
          image: mongo
          command:
            - &quot;mongod&quot;
            - &quot;--port&quot;
            - &quot;27017&quot;
            - &quot;--bind_ip&quot;
            - &quot;0.0.0.0&quot;
            - &quot;--replSet&quot;
            - &quot;ShardX&quot;
            - &quot;--dbpath&quot;
            - &quot;/mongo-disk&quot;
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
          ports:
            - containerPort: 27017
          volumeMounts:
            - name: mongo-shardX-persistent-storage-claim
              mountPath: /mongo-disk
  volumeClaimTemplates:
  - metadata:
      name: mongo-shardX-persistent-storage-claim
      annotations:
        volume.beta.kubernetes.io/storage-class: &quot;fast&quot;
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      resources:
        requests:
          storage: DB_DISK
</pre></div>


<div class="highlight"><pre><span></span>#replace &#39;shardX&#39; &amp; &#39;ShardX&#39; with shard1 &amp; Shard1. Mind case sensitivity.
sed -e &quot;s/shardX/shard1/g; s/ShardX/Shard1/g; s/NAMESPACE_ID/daemonsl/g; s/DB_DISK/10Gi/g&quot; mongodb-maindb-service-stateful.yaml &gt; tmp-mongodb-maindb-service-stateful.yaml
kubectl apply -f tmp-mongodb-maindb-service-stateful.yaml

#replace &#39;shardX&#39; &amp; &#39;ShardX&#39; with shard2 &amp; Shard2. Mind case sensitivity.
sed -e &quot;s/shardX/shard2/g; s/ShardX/Shard2/g; s/NAMESPACE_ID/daemonsl/g; s/DB_DISK/10Gi/g&quot; mongodb-maindb-service-stateful.yaml &gt; tmp-mongodb-maindb-service-stateful.yaml
kubectl apply -f tmp-mongodb-maindb-service-stateful.yaml

#run command to see Pods &amp; Services spinning up
kubectl get svc,po --namespace=daemonsl
</pre></div>


<p>Till here, we have accomplished statefulsets container running along with headless services and mounted a SSD volume that fulfills Pods requirement.</p>
<div class="highlight"><pre><span></span>kubectl get persistentvolumes

# Get persistent volume claims
kubectl get persistentvolumeclaims --namespace=daemonsl
</pre></div>


<hr>
<h4>3.3 Mongos Deployment</h4>
<p>We have configdb and maindb pods up and running. We will spin up mongos server to establish a sharding cluster. Replace <code>NAMESPACE_ID</code> with <code>daemonsl</code>, or whatever name you have defined.</p>
<p>We have configured config server information in mongos using <code>--configdb</code> flag with unique network identifiers of configdb pod. DNS of statefulset pods goes by convention <code>&lt;POD_NAME&gt;.&lt;SERVICE_NAME&gt;.&lt;NAMESPACE&gt;.svc.&lt;CLUSTER_DOMAIN&gt;</code>.</p>
<p><strong>Reference : </strong> <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-network-id">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-network-id</a></p>
<div class="highlight"><pre><span></span><span class="n">apiVersion</span><span class="o">:</span> <span class="n">apps</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">Deployment</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">mongos</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="n">NAMESPACE_ID</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">replicas</span><span class="o">:</span> <span class="mi">2</span>
  <span class="n">template</span><span class="o">:</span>
    <span class="n">metadata</span><span class="o">:</span>
      <span class="n">labels</span><span class="o">:</span>
        <span class="n">role</span><span class="o">:</span> <span class="n">mongos</span>
        <span class="n">tier</span><span class="o">:</span> <span class="n">routers</span>
    <span class="n">spec</span><span class="o">:</span>
      <span class="n">affinity</span><span class="o">:</span>
        <span class="n">podAntiAffinity</span><span class="o">:</span>
          <span class="n">preferredDuringSchedulingIgnoredDuringExecution</span><span class="o">:</span>
          <span class="o">-</span> <span class="n">weight</span><span class="o">:</span> <span class="mi">100</span>
            <span class="n">podAffinityTerm</span><span class="o">:</span>
              <span class="n">labelSelector</span><span class="o">:</span>
                <span class="n">matchExpressions</span><span class="o">:</span>
                <span class="o">-</span> <span class="n">key</span><span class="o">:</span> <span class="n">tier</span>
                  <span class="n">operator</span><span class="o">:</span> <span class="n">In</span>
                  <span class="n">values</span><span class="o">:</span>
                  <span class="o">-</span> <span class="n">routers</span>
              <span class="n">topologyKey</span><span class="o">:</span> <span class="n">kubernetes</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">hostname</span>
      <span class="n">terminationGracePeriodSeconds</span><span class="o">:</span> <span class="mi">10</span>
      <span class="n">containers</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">name</span><span class="o">:</span> <span class="n">mongos</span><span class="o">-</span><span class="n">container</span>
          <span class="n">image</span><span class="o">:</span> <span class="n">mongo</span>
          <span class="n">command</span><span class="o">:</span>
            <span class="o">-</span> <span class="s2">&quot;mongos&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;--port&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;27017&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;--bind_ip&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;0.0.0.0&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;--configdb&quot;</span>
            <span class="o">-</span> <span class="s2">&quot;mongodb-configdb-0.mongodb-configdb-headless-service.daemonsl.svc.cluster.local:27019&quot;</span>
          <span class="n">resources</span><span class="o">:</span>
            <span class="n">requests</span><span class="o">:</span>
              <span class="n">cpu</span><span class="o">:</span> <span class="mi">50</span><span class="n">m</span>
              <span class="n">memory</span><span class="o">:</span> <span class="mi">100</span><span class="n">Mi</span>
          <span class="n">ports</span><span class="o">:</span>
            <span class="o">-</span> <span class="n">containerPort</span><span class="o">:</span> <span class="mi">27017</span>
</pre></div>


<div class="highlight"><pre><span></span>sed -e &quot;s/NAMESPACE_ID/daemonsl/g&quot; mongodb-mongos-deployment-service.yaml &gt; tmp-mongodb-mongos-deployment-service.yaml
kubectl apply -f tmp-mongodb-mongos-deployment-service.yaml
</pre></div>


<p><br></p>
<hr>
<p><br></p>
<h3>4. Configure Sharding</h3>
<p>Now, we have <code>mongos, configdb</code> and <code>maindb</code> up and running. We need to create Replicaset in MainDB servers that we are intending to make shard. We will run <code>rs.initiate()</code> command to make <code>PRIMARY</code> replica. Since we are going with one replica member in each shard. We will run initiate command in each of the <code>maindb</code> pod.</p>
<div class="highlight"><pre><span></span><span class="nt">echo</span> <span class="s2">&quot;Replicaset Init mongodb-shard1-0 &quot;</span>
<span class="nt">kubectl</span> <span class="nt">exec</span> <span class="nt">--namespace</span><span class="o">=</span><span class="nt">daemonsl</span> <span class="nt">mongodb-shard1-0</span> <span class="nt">-c</span> <span class="nt">mongodb-shard1-container</span> <span class="nt">--</span> <span class="nt">mongo</span> <span class="nt">--port</span> <span class="nt">27017</span> <span class="nt">--eval</span> <span class="s2">&quot;rs.initiate({_id: \&quot;Shard1\&quot;</span><span class="o">,</span> <span class="nt">version</span><span class="o">:</span> <span class="nt">1</span><span class="o">,</span> <span class="nt">members</span><span class="o">:</span> <span class="cp">[</span> <span class="p">{</span><span class="nx">_id</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="nx">host</span><span class="p">:</span> <span class="o">\</span><span class="s2">&quot;mongodb-shard1-0.mongodb-shard1-headless-service.daemonsl.svc.cluster.local:27017</span><span class="se">\&quot;</span><span class="s2">} ] });&quot;</span>


<span class="nx">echo</span> <span class="s2">&quot;Replicaset Init mongodb-shard2-0 &quot;</span>  
<span class="nx">kubectl</span> <span class="nx">exec</span> <span class="o">--</span><span class="n">namespace</span><span class="o">=</span><span class="nx">daemonsl</span> <span class="nx">mongodb</span><span class="na">-shard2</span><span class="o">-</span><span class="mi">0</span> <span class="na">-c</span> <span class="nx">mongodb</span><span class="na">-shard2-container</span> <span class="o">--</span> <span class="nx">mongo</span> <span class="o">--</span><span class="nx">port</span> <span class="mi">27017</span> <span class="o">--</span><span class="nx">eval</span> <span class="s2">&quot;rs.initiate({_id: </span><span class="se">\&quot;</span><span class="s2">Shard2</span><span class="se">\&quot;</span><span class="s2">, version: 1, members: [ {_id: 0, host: </span><span class="se">\&quot;</span><span class="s2">mongodb-shard2-0.mongodb-shard2-headless-service.daemonsl.svc.cluster.local:27017</span><span class="se">\&quot;</span><span class="s2">} ] });&quot;</span>
</pre></div>


<p>Above lines, will make both pods PRIMARY of their respective replicaset. You can even go into container to verify replicaset status by running <code>rs.status()</code> command.</p>
<p>We are proceeding now to add shards to mongos server. We will run below command in any of the mongos pod. Mongos server are stateless application, they save the configuration in configdb server which we have made stateful application by declaring them under statefulset container.</p>
<div class="highlight"><pre><span></span><span class="nt">echo</span> <span class="s2">&quot;Adding Shard 1 : Shard1 &quot;</span>
<span class="nt">kubectl</span> <span class="nt">exec</span> <span class="nt">--namespace</span><span class="o">=</span><span class="nt">daemonsl</span> <span class="o">$(</span><span class="nt">kubectl</span> <span class="nt">get</span> <span class="nt">pod</span> <span class="nt">-l</span> <span class="s2">&quot;tier=routers&quot;</span> <span class="nt">-o</span> <span class="nt">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items</span><span class="cp">[</span><span class="mi">0</span><span class="cp">]</span><span class="s1">.metadata.name}&#39;</span> <span class="nt">--namespace</span><span class="o">=</span><span class="nt">daemonsl</span> <span class="o">)</span> <span class="nt">-c</span> <span class="nt">mongos-container</span> <span class="nt">--</span> <span class="nt">mongo</span> <span class="nt">--port</span> <span class="nt">27017</span> <span class="nt">--eval</span> <span class="s2">&quot;sh.addShard(\&quot;Shard1/mongodb-shard1-0.mongodb-shard1-headless-service.daemonsl.svc.cluster.local:27017\&quot;);&quot;</span>

<span class="nt">echo</span> <span class="s2">&quot;Adding Shard 2 : Shard2 &quot;</span>
<span class="nt">kubectl</span> <span class="nt">exec</span> <span class="nt">--namespace</span><span class="o">=</span><span class="nt">daemonsl</span> <span class="o">$(</span><span class="nt">kubectl</span> <span class="nt">get</span> <span class="nt">pod</span> <span class="nt">-l</span> <span class="s2">&quot;tier=routers&quot;</span> <span class="nt">-o</span> <span class="nt">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items</span><span class="cp">[</span><span class="mi">0</span><span class="cp">]</span><span class="s1">.metadata.name}&#39;</span> <span class="nt">--namespace</span><span class="o">=</span><span class="nt">daemonsl</span> <span class="o">)</span> <span class="nt">-c</span> <span class="nt">mongos-container</span> <span class="nt">--</span> <span class="nt">mongo</span> <span class="nt">--port</span> <span class="nt">27017</span> <span class="nt">--eval</span> <span class="s2">&quot;sh.addShard(\&quot;Shard2/mongodb-shard2-0.mongodb-shard2-headless-service.daemonsl.svc.cluster.local:27017\&quot;);&quot;</span>
</pre></div>


<p>Now, we can get into one of the mongos container to verify the sharding status of cluster. All the above steps can be automated to make any number of shards within your cluster and thus concepts are very trivial to support stateful application powered by GKE.</p>
<hr>
<h4>Test Sharding</h4>
<p>To test that the sharded cluster is working properly, connect to the container running the first "mongos" router, then use the Mongo Shell to authenticate, enable sharding on a specific database &amp; collection, add some test data to this collection and then view the status of the Sharded cluster and collection:</p>
<div class="highlight"><pre><span></span>$ kubectl <span class="nb">exec</span> -it <span class="k">$(</span>kubectl get pod -l <span class="s2">&quot;tier=routers&quot;</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items[0].metadata.name}&#39;</span><span class="k">)</span> -c mongos-container bash
$ mongo
&gt; sh.enableSharding<span class="o">(</span><span class="s2">&quot;&lt;Database_name&gt;&quot;</span><span class="o">)</span><span class="p">;</span>
&gt; sh.status<span class="o">()</span><span class="p">;</span>
&gt; use admin
&gt; db.admin.runCommand<span class="o">(</span><span class="s2">&quot;getShardMap&quot;</span><span class="o">)</span>
</pre></div>


<hr>
<h4>Tearing &amp; Cleaning Down the Kubernetes Environment</h4>
<p><strong>Important:</strong> This step is required to ensure you aren't continuously charged by Google Cloud for an environment you no longer need.</p>
<p>Run the following script to undeploy the MongoDB Services &amp; StatefulSets/Deployments plus related Kubernetes resources, followed by the removal of the GCE disks. This script is available in repository.</p>
<div class="highlight"><pre><span></span>$ sh teardown.sh   <span class="c1">#To delete all resources provisioned above</span>
</pre></div>


<hr>
<h3>Factors Addressed in this Demonstration</h3>
<ul>
<li>Deployment of a MongoDB on the Google Kubernetes Engine</li>
<li>Use of Kubernetes StatefulSets and PersistentVolumeClaims to ensure data is not lost when containers are recycled</li>
<li>Proper configuration of a MongoDB Sharded Cluster for Scalability with each Shard being a Replica Set for full resiliency</li>
<li>Controlling Anti-Affinity for Mongod Replicas to avoid a Single Point of Failure</li>
</ul>
<hr>
<p><strong>Github reference : <a href="https://github.com/sunnykrGupta/gke-mongodb-shards">https://github.com/sunnykrGupta/gke-mongodb-shards</a></strong></p>
<p><strong>Credit :</strong> This blog is based on workdone by <a href="https://twitter.com/TheDonester">Paul Done</a></p>
<hr>
<h4>Must read below resources in order to get detailed understanding :</h4>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset</a></li>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">https://kubernetes.io/docs/concepts/services-networking/service/#headless-services</a></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-network-id">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#stable-network-id</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#gce">https://kubernetes.io/docs/concepts/storage/storage-classes/#gce</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">https://kubernetes.io/docs/concepts/storage/persistent-volumes/</a></li>
<li><a href="http://blog.kubernetes.io/2017/03/dynamic-provisioning-and-storage-classes-kubernetes.html">http://blog.kubernetes.io/2017/03/dynamic-provisioning-and-storage-classes-kubernetes.html</a></li>
<li><a href="http://blog.kubernetes.io/2017/03/advanced-scheduling-in-kubernetes.html">http://blog.kubernetes.io/2017/03/advanced-scheduling-in-kubernetes.html</a></li>
</ul>
<hr>
  </div>
  <div class="article_meta">
    <p>Posted on: Sun 31 December 2017</p>
    <p>Category: <a href="https://sunnykrGupta.github.io/category/blog.html">Blog</a>
 &ndash; Tags:
      <a href="https://sunnykrGupta.github.io/tag/kubernetes.html">Kubernetes</a>,      <a href="https://sunnykrGupta.github.io/tag/mongodb.html">Mongodb</a>,      <a href="https://sunnykrGupta.github.io/tag/statefulsets.html">StatefulSets</a>    </p>
  </div>
  <section>
      <p id="post-share-links">
          Share on:
          <a href="https://twitter.com/home?status=Sharded%20Mongodb%20in%20Kubernetes%20StatefulSets%20on%20GKE%20https%3A//sunnykrGupta.github.io/sharded-mongodb-in-kubernetes-statefulsets-on-gke.html" target="_blank" title="Share on Twitter"><img src="https://sunnykrGupta.github.io/theme/images/Share/twitter.svg" alt="twitter"></a>
          <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//sunnykrGupta.github.io/sharded-mongodb-in-kubernetes-statefulsets-on-gke.html" target="_blank" title="Share on Facebook"><img src="https://sunnykrGupta.github.io/theme/images/Share/facebook.svg" alt="facebook"></a>
          <a href="https://plus.google.com/share?url=https%3A//sunnykrGupta.github.io/sharded-mongodb-in-kubernetes-statefulsets-on-gke.html" target="_blank" title="Share on Google Plus"><img src="https://sunnykrGupta.github.io/theme/images/Share/googleplus.svg" alt="google+"></a>
          <a href="mailto:?subject=Sharded%20Mongodb%20in%20Kubernetes%20StatefulSets%20on%20GKE&amp;body=https%3A//sunnykrGupta.github.io/sharded-mongodb-in-kubernetes-statefulsets-on-gke.html" target="_blank" title="Share via Email"><img src="https://sunnykrGupta.github.io/theme/images/Share/mail.svg" alt="email"></a>
      </p>
  </section>

  <div id="article_comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_identifier = "sharded-mongodb-in-kubernetes-statefulsets-on-gke.html";
        (function() {
             var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
             dsq.src = 'https://sunnydaemon.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
         })();
    </script>
  </div>

</article>


    <div id="ending_message">
      <p>&copy; Sunny Kumar. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme by Sunny Kumar on <a href="https://github.com/sunnykrgupta/pelican-svbhack-responsive" target="_blank">github</a>. </p>
    </div>
  </main>

  <div id="right-feed">
    <!--
    <a class="twitter-timeline" href="" data-widget-id="605800181926199296">Tweets by </a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
    -->

    <a class="twitter-timeline" data-lang="en" data-width="230" data-height="700" data-theme="dark" href="https://twitter.com/Sunny_KrGupta?ref_src=twsrc%5Etfw">Tweets by Sunny_KrGupta</a>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  </div>
</body>
</html>